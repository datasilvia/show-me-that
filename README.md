# Computer vision 
## Nuestro proyecto

Decidimos hacer un proyecto que emplease computer vision porque queríamos investigar y aprender sobre esta tecnología.


## ¿Qué es Computer Vision?


Es la tecnología que permite analizar información visual. Hace que la máquina “vea” y procese esa información.

El término Computer Vision (Visión Artificial) es un campo de Inteligencia Artificial que enseña a los ordenadores a ‘ver’ y entender el contenido de las imágenes. 
En otras palabras, tiene como objetivo dar a las computadoras una comprensión visual del mundo.



## Cómo funciona Computer Vision?

Las aplicaciones de Computer Vision utilizan entradas que proceden de sensores, inteligencia artificial, aprendizaje automático y aprendizaje profundo para replicar el funcionamiento de la visión humana. Las aplicaciones de visión artificial ejecutan algoritmos que se entrenan con enormes cantidades de datos visuales o imágenes en la nube. Reconocen patrones en los datos visuales y usan esos patrones para determinar el contenido de otras imágenes.



Cómo se analiza una imagen con Computer Vision

    Un sensor captura una imagen. A menudo, este sensor es simplemente una cámara, pero puede ser una cámara de vídeo, un dispositivo médico de diagnóstico por imagen o cualquier otro tipo de dispositivo que capture una imagen para analizarla.

    A continuación, se envía la imagen a un dispositivo de interpretación. El dispositivo de interpretación usa el reconocimiento de patrones para descomponer la imagen, comparar los patrones que contiene con su biblioteca de patrones conocidos y determinar si hay contenido en la imagen que coincida. El patrón puede ser algo general, como la apariencia de un determinado tipo de objeto, o podría basarse en identificadores únicos, como los rasgos faciales.

    Un usuario solicita información específica sobre una imagen y el dispositivo de interpretación proporciona la información solicitada en función del análisis que ha realizado de la imagen.

Aprendizaje profundo y Computer Vision

    Las modernas aplicaciones de Computer Vision están dejando de usar métodos estadísticos para analizar las imágenes y, cada vez más, se basan en lo que se conoce como aprendizaje profundo. Con el aprendizaje profundo, una aplicación de visión artificial ejecuta un tipo de algoritmo denominado red neuronal, que le permite proporcionar análisis más precisos de las imágenes. Además, el aprendizaje profundo permite a un programa de Computer Vision conservar la información de cada imagen que analiza, de modo que, cuanto más se usa, mejor es su precisión.




## Capacidades de Computer Vision 

1. Clasificación de objetos:
El sistema clasifica los objetos de una imagen en función de una categoría definida. Por ejemplo, con la clasificación de objetos, un equipo podría distinguir a las personas de los objetos en una foto y determinar cuántas personas aparecen en la foto.

2. Identificación de objetos:
El sistema identifica un objeto determinado en una foto, un vídeo o una imagen. Por ejemplo, con la identificación de objetos, el sistema podría no solo distinguir a las personas de una foto, sino también analizar su apariencia para determinar la identidad o los rasgos de esas personas.

3. Seguimiento de objetos:
El sistema analiza un vídeo para procesar la ubicación de un objeto en movimiento a lo largo del tiempo. Por ejemplo, con el seguimiento de objetos, una cámara de vigilancia de un aparcamiento podría identificar los automóviles y proporcionar información sobre su ubicación y movimientos a lo largo del tiempo.

4. El sistema identifica las letras y los números de las imágenes y convierte el texto en texto codificado por máquina que otras aplicaciones informáticas pueden leer o los usuarios pueden editar.



## Usos del Computer Vision


Organización de contenido

Computer Vision se puede usar para identificar a personas u objetos en fotografías y organizarlos en función de esa identificación. Las aplicaciones de reconocimiento de fotografías como esta se suelen usar para el almacenamiento de fotografías y en los medios sociales.




Extracción de texto

El reconocimiento óptico de caracteres puede usarse para mejorar la detectabilidad de la información contenida en grandes cantidades de texto y para habilitar el procesamiento de documentos en escenarios de automatización de procesos robóticos. También resulta de utilidad para mejorar la accesibilidad en la obtención de información para personas con dificultades de visión.




Realidad aumentada

Computer Vision puede detectar y seguir objetos físicos en tiempo real. Esta información se utiliza después para colocar objetos virtuales en un entorno físico de forma realista.



Agricultura

Se pueden analizar imágenes de cultivos tomadas por satélites, drones o aviones para supervisar las cosechas, detectar la aparición de malas hierbas o identificar una deficiencia de nutrientes en el cultivo.




Vehículos autónomos

Los automóviles sin conductor utilizan la identificación y el seguimiento de los objetos en tiempo real para recopilar información sobre lo que ocurre alrededor del automóvil y dirigirlo en consecuencia.




Sector sanitario

Las fotos o imágenes capturadas por otros dispositivos médicos se pueden analizar para ayudar a los doctores a identificar problemas y realizar diagnósticos con más rapidez y precisión.




Deportes

La detección y el seguimiento de objetos se utilizan para el análisis de estrategias y partidos.




Fabricación

Computer Vision puede supervisar la maquinaria de fabricación con fines de mantenimiento. También se puede usar para supervisar la calidad y el empaquetado de los productos en una línea de producción.



Control de calidad y detección de fallos y defectos.



Análisis espacial

El sistema identifica a personas u objetos (como automóviles en carreteras, o clientes en establecimientos) y sigue su movimiento dentro de ese espacio, pudiendo calcular distancias entre un objetos/persona y otro, tiempo de permanencia en el lugar, etc.




Reconocimiento facial

Computer Vision se puede usar para identificar a personas y hacer comprobación de identidad. Útil en control de acceso a edificios o espacios, o login en aplicaciones.



## Casos reales de uso de Computer Vision

1. Logística | Control de calidad

El proceso de inspección de búsqueda de defectos tradicionalmente estaba a cargo de un profesional que requería mantenerse atento durante largas y tediosas horas. Debido a estas condiciones de trabajo, las omisiones o errores eran comunes.

La visión artificial impulsada por IA contrarresta el factor humano en operaciones repetitivas lo que da como resultado mayor fiabilidad en los controles. Estas soluciones pueden aplicarse en una gran variedad de industrias.

Amazon, por ejemplo, utiliza sistemas de visión por computadora que pueden ayudar a descargar un tráiler de inventario en sólo 30 minutos, una labor que podría tomar horas sin este tipo de soluciones.



2. La visión artificial aplicada a un robot paletizador

La visión artificial emula a la visión humana, pero con una gran diferencia. La visión humana tiene características que tienden a lo cualitativo, mientras que la artificial se centra más en observaciones cuantitativas. Por eso se convierte en una herramienta extraordinaria a la hora de hacer mediciones exactas: tamaños, paralelismos, rectitud.

Este sistema, aplicado a un robot paletizador -de tableros, por ejemplo- permite comprobar que el grosor de la plancha sea el correcto, verificar los ángulos de corte, o que no haya ningún desperfecto en la superficie. Si el robot detectase que algo no cumple con los criterios establecidos, desecharía la plancha de madera a una dársena de descarte.


3. Automoción

Tesla es el único fabricante de vehículos eléctricos que desarrolla autonomía para apostar completamente por la visión por computadora en lugar de un enfoque basado en LiDAR.

LiDAR significa «detección de luz y alcance» y es esencialmente un sonar que utiliza ondas láser de pulso para trazar un mapa de la distancia entre los objetos y construir mapas de alta definición del área. Una simple analogía puede ilustrar la diferencia conceptual entre Computer Vision y LiDAR. Imagínate dos estudiantes, donde uno simplemente está abarrotando y memorizando el contenido (LiDAR), mientras que el otro mientras que el otro está tratando de entender realmente lo que ve, es decir todo su entorno todo lo material y aprenderlo de verdad (Tesla FSD).

El estudiante que aprendió el material (Tesla FSD) podrá responder las preguntas del examen correctamente, incluso si las preguntas del examen se intercambian, las preguntas se reformulan o se agregan nuevos componentes a las preguntas.

El director de inteligencia artificial de Tesla, Andrej Karpathy, explica en este video cómo Tesla obtiene imágenes para entrenar la detección de objetos:

Tesla sabe muy bien el significado real de la aplicación de Computer Vision. En comunicación con la tecnología de IA, todos los modelos Tesla llevan instaladas decenas de cámaras. Utilizando la visibilidad 360, su sistema AutoPilot tiene la capacidad de conducir el vehículo sin la supervisión humana.


4. Visión artificial industrial en el control de calidad

Este es otro de los sectores donde más se explota por ahora esta característica de la robótica. En segundos, haciendo uso de sensores especiales un robot puede optimizar todo el proceso de selección y de control de calidad tanto en piezas del sector automotriz, como frutas y alimentos defectuosos en los sectores alimenticios de todo tipo.


5. Retail y Seguridad

Amazon abrió las puertas de su primera tienda Amazon Go en Seattle en enero de 2018 después de pasar un año probando su tecnología Just Walk Out en sus empleados en su sede. El gigante tecnológico ahora tiene 27 tiendas en los EE. UU. En Amazon Go donde los clientes no tienen que pasar por caja, y por lo tanto no tienen que hacer colas innecesarias, porque, de hecho, no hay cajeros.

El concepto de tienda permite que un cliente ingrese a una tienda Amazon Go escaneando un código QR de su aplicación de Amazon en el acceso a la tienda para permitirle la entrada, recoger un producto y salir nuevamente sin hacer cola para pagar en cajero.

La tecnología de visión por computadora, a diferencia de la identificación por radiofrecuencia (RFID) o los sensores de peso en los estantes, les sirve para detectar lo que un cliente lleva consigo. Amazon luego envía por correo electrónico un recibo después de la compra.

En este video explicativo, podemos ver que esto lo consiguen instalando cientos de cámaras en el recinto del supermercado en combinación con la tecnología de Computer Vision.


Aunque Amazon Go fue la pionera, un puñado de nuevas empresas están aprovechando esta oportunidad en la actualidad, incluidas Standard Cognition, Grabango, Trigo Vision, Zippin y AiFi. Standard Cognition, el mejor financiado de estos competidores, anunció una ronda de financiación de US$ 150 millones del Vision Fund de SoftBank a principios de 2021.


6. Seguros

El negocio de los seguros depende en gran medida de la evaluación visual de los activos: para fijar el precio y suscribir pólizas con precisión, por ejemplo, así como para determinar el alcance de los daños después de un accidente a efectos de reclamaciones. Como en otras industrias, la visión por computadora ofrece la oportunidad de realizar este análisis visual de forma más rápida, económica y precisa de lo que se hace en la actualidad.

Cape Analytics y Betterview son dos nuevas empresas que aplican la visión por computadora al seguro de la vivienda. Usando datos geoespaciales, pueden evaluar automáticamente de qué material está hecho un edificio, en qué condición se encuentra el techo, cuál es la superficie del techo, cuántos escombros de jardín tiene la propiedad, qué tan cerca está una estructura de la vegetación, y cientos de otros factores que determinan colectivamente el perfil de riesgo de la propiedad y el precio óptimo de la póliza de seguro.


7. Salud: una salud inteligente a través de IA y la nube

Microsoft pone a disposición un software llamado InnerEye, que es capaz de visualizar e identificar tumores u otras anomalías en las radiografías (rayos X). Los radiólogos pueden subir una radiografía tridimensional, y el software colorea las zonas que presentan anomalías, con el fin de prestar mayor atención a dicha zona.

InnerEye puede escanear 10,000 imágenes por hora y utiliza un usuario biónico: el cerebro humano como parte de una red de inteligencia artificial personalizada


El objetivo de InnerEye es democratizar la inteligencia artificial para el análisis de imágenes médicas y capacitar a los profesionales de institutos de investigación, hospitales, organizaciones de ciencias de la vida y proveedores de atención médica para construir sus propios modelos de inteligencia artificial para imágenes médicas utilizando Microsoft Azure.


8. Banca

Este sector también está sacándole partido a la tecnología de CV. Existen sistemas como Mitek Systems que realizan un reconocimiento de imágenes con el fin de clasificar documentos, extraer información e identificar a los individuos.

La verificación de identidad, incluido el análisis biométrico, la tecnología de captura de imágenes y la verificación de tarjetas identificativas, permite a las entidades incorporar nuevos usuarios con total seguridad, verificar identidades en cuestión de segundos y reforzar la seguridad frente a los delitos cibernéticos.

Esto facilita trámites como no tener que acudir a una sucursal para abrir una nueva cuenta bancaria. El usuario se identifica utilizando la cámara de su teléfono móvil, sube la documentación necesaria, y se ahorra las largas colas que se solían hacer en los bancos.




## ¿Qué es la detección de objetos?
Es una técnica para detectar objetos en una imagen o en un video.
La detección de objetos se muestra mediante una bounding box y una etiqueta.


## Diferencia entre Object Classification, Object Detection y Object Segmentation

1. Object Classification:
Es un tipo de reconocimiento de imágenes que identifa qué objeto aparece en una imagen y dónde está localizado en dicha imagen.

2. Object Segmentation:
Es el tipo de reconocimiento de objetos que se usa para identificar y separar los distintos objetos en una imagen (a nivel de píxel)



## Historia de la detección de objetos:

Empezó en los años 70, cuando se empezaron a crear métodos automatizados para la detección de objetos.
El primer algoritmo de detección de objetos se basaba en características como los bordes y esquinas.
En 2001 Viola Jones creó el reconocimiento facial.
Se usaba en smarphones y cámaras. 

En 2005 se empezó a usar el Histogram of Oriented Gradients, que se centraba en la forma del objeto.

Luego vinieron las redes neuronales.
Y las redes neuronales convolucionales.

Bruce Force creo un método para utilizar las redes neuronales convolucionales como modelos de detección, pero resultó poco eficiente.
Así que se crearon las RCNN, Regiones con Redes Neuronales Convolucionales, que usaban regiones seleccionadas para aplicar los clasificadores.
Esto daba buenos resultados, pero era lento.

En 2015 apareció Yolo.
Lo que hacían las regiones con redes neuronales convolucionales en varias iteraciónes, Yolo la hacía en una sola.


## Métricas de evaluación de rendimiento.

Hay que medir cómo de buena es la localización del objeto, y cómo de buena es la clasificación del mismo.

- IoU (Intersecction Over Union): 
Mide la localización. Te dice cómo de cerca está la bounding box de la predicción de la bounding box correcta. 
Es un valor entr 0 y 1, siendo 1 la mejor valoración, que sucede cuando la bounding box de la predicción y la de la realidad están superpuestas.
Se calcula dividiendo el área de la intersección entre el área de la unión de ambas bounding boxes.

- mAP (Mean average precission): 
Mide la clasificación.
Se basa en:
    - Precision: Positivos del total de predicciones positivas.
    - Recall: Positivos del total de predicciones.

Ambas métricas, precision y recall se combinana en el Average Precision (cuando es para una clase). 
Si hay más de una clase, se hace la media del Average Precision.



## Tecnologias usadas en el proyecto

### Python

### Tensor Flow

### Keras

### PyTorch

### OpenCV

### Yolov5

### Ultralytics Roboflow

Roboflow tiene herramientas para:
- Obtención de imágenes:
    - Universe https://universe.roboflow.com
    Es un repositorio con más de 250.000 datasets de imágenes
    - Collect https://github.com/roboflow/roboflow-collect
- Carga y conversión de datos
- Etiquetado de imágenes (Roboflow anotate) 
    - Tiene un asistente de etiquetado
    - Si formas parte de un equipo, puedes asignar tareas de etiquetado a otros mienbros del equipo
- Ver el estado de tu dataset (Roboflow Health Check)
    - Distintas estadísticas como tamaño medio de las imágenes del conjunto, equilibrio de clases, mapa de calor que muestra dónde se encuentran las anotaciones en las imágenes, etc. 
- Exportación de datos en más de 40 formatos
- Data Augmentation (Para aumentar el tamaño del dataset) Te permite efectuar los siguientes cambios:
    - Rotación
    - Flip
    - Modificar el brillo
    - Crop
- Entrenamiento de modelos
- Implantación de modelos
- Obtención de modelos creados por otros usuarios
- Subir tu propio modelo para que sea utilizado por otros usuarios


Competidores de Roboflow:
- AWS SageMaker
- Google Cloud AutoML
- Microsoft Azure Custom Vision
- Labelbox
- SuperAnotate

- LabelImg